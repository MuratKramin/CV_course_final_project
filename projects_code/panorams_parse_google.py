import json
import csv
import time
import random
from pathlib import Path
from streetlevel import streetview
from tqdm import tqdm

from datetime import datetime

# === –ü—É—Ç–∏ ===
DATA_FILE = Path("all_city_coordinates.json")
UPDATED_FILE = Path("panoramas/all_city_coordinates_updated.json")
PANORAMA_DIR = Path("panoramas")
IMAGE_DIR = PANORAMA_DIR / "images"
CSV_PATH = PANORAMA_DIR / "panoramas.csv"
SEEN_IDS_PATH = PANORAMA_DIR / "seen_ids.txt"
LOG_PATH = PANORAMA_DIR / "log.txt"

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
TARGET_COUNT = 40000  # –æ–±—â–µ–µ —á–∏—Å–ª–æ –Ω—É–∂–Ω—ã—Ö –ø–∞–Ω–æ—Ä–∞–º (–º–æ–∂–Ω–æ –±–æ–ª—å—à–µ)
DELAY_BASE = 1.5
DELAY_JITTER = 1.0

ZOOM_LEVEL = 2  # –∏–ª–∏ –ª—é–±–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å
SOURCE = "google"  # –∏–º—è —Å–µ—Ä–≤–∏—Å–∞, –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –º–µ–Ω—è—Ç—å –¥–ª—è Google, Mapillary –∏ –¥—Ä.


# === –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ===
PANORAMA_DIR.mkdir(exist_ok=True)
IMAGE_DIR.mkdir(exist_ok=True)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è pending ===
# with open(DATA_FILE, "r", encoding="utf-8") as f:
#     coords = json.load(f)

def log(msg: str, print_also: bool = False):
    timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    line = f"{timestamp} {msg}"
    with open(LOG_PATH, "a", encoding="utf-8") as f_log:
        f_log.write(line + "\n")
    if print_also:
        print(line)

# === –ó–∞–≥—Ä—É–∑–∫–∞ seen_ids.txt ===
seen_ids = set()
if SEEN_IDS_PATH.exists():
    with open(SEEN_IDS_PATH, "r", encoding="utf-8") as f:
        seen_ids = set(line.strip() for line in f if line.strip())

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
if UPDATED_FILE.exists():
    print("üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –∏–∑ all_city_coordinates_updated.json")
    with open(UPDATED_FILE, "r", encoding="utf-8") as f:
        coords = json.load(f)
else:
    print("üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π all_city_coordinates.json")
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        coords = json.load(f)

# === –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –∏–∑ seen_ids
restored = 0
for pt in coords:
    pano_id = pt.get("pano_id")
    if pano_id and pano_id in seen_ids and pt.get("status") != "done":
        pt["status"] = "done"
        restored += 1

if restored > 0:
    print(f"üîÅ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored} –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º 'done' –ø–æ seen_ids.txt")
# === –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–æ —Å—Ç–∞—Ç—É—Å—É ===


#pending_coords = [pt for pt in coords if pt["status"] == "pending"]
pending_coords = list(filter(lambda pt: pt.get("status") == "pending", coords))

random.shuffle(pending_coords)

# === –ó–∞–≥—Ä—É–∑–∫–∞ seen_ids.txt ===
seen_ids = set()
if SEEN_IDS_PATH.exists():
    with open(SEEN_IDS_PATH, "r", encoding="utf-8") as f:
        seen_ids = set(line.strip() for line in f if line.strip())

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ CSV ===
csv_exists = CSV_PATH.exists()
f_csv = open(CSV_PATH, "a", newline="", encoding="utf-8")
writer = csv.writer(f_csv)
if not csv_exists:
    writer.writerow(["id", "latitude", "longitude", "city", "date", "zoom", "source","request_lat", "request_lon"])


    f_csv.flush()

# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º ===
count = len(seen_ids)
progress = tqdm(pending_coords, desc="üîç –ü–∞—Ä—Å–∏–Ω–≥ –ø–∞–Ω–æ—Ä–∞–º", unit="—Ç–æ—á–µ–∫")

save_every = 1
processed_since_last_save = 0


for point in progress:
    if count >= TARGET_COUNT:
        break

    lat, lon = point["lat"], point["lon"]
    city = point["city"]
    point_id = f"{lat}_{lon}"

    try_attempts = 0
    success = False

    while try_attempts < 2 and not success:
        try:
            pano = streetview.find_panorama(lat, lon)
            if pano and pano.id not in seen_ids:
                image_path = IMAGE_DIR / f"{pano.id}.jpg"
                streetview.download_panorama(pano, str(image_path), zoom=ZOOM_LEVEL)

                writer.writerow([pano.id, pano.lat, pano.lon, city, pano.date, ZOOM_LEVEL, SOURCE, lat, lon])
                f_csv.flush()
                with open(SEEN_IDS_PATH, "a", encoding="utf-8") as f_seen:
                    f_seen.write(pano.id + "\n")

                seen_ids.add(pano.id)
                point["status"] = "done"
                point["pano_id"] = pano.id
                point["zoom"] = ZOOM_LEVEL
                point["source"] = SOURCE
                count += 1
                success = True

                print(f"‚úÖ [{count}] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–∞–Ω–æ—Ä–∞–º–∞ {pano.id} ‚Äî {city} ({pano.lat}, {pano.lon}) ‚Äî {pano.date}")
                log(
                    f"‚úÖ [{count}] –ü–∞–Ω–æ—Ä–∞–º–∞ {pano.id} ‚Äî {city} "
                    f"(–ù–∞–π–¥–µ–Ω–æ: {pano.lat:.6f}, {pano.lon:.6f}; –ó–∞–ø—Ä–æ—à–µ–Ω–æ: {lat:.6f}, {lon:.6f}) ‚Äî {pano.date}"
                )


                processed_since_last_save += 1
                if processed_since_last_save >= save_every:
                    with open(UPDATED_FILE, "w", encoding="utf-8") as f:
                        json.dump(coords, f, indent=2, ensure_ascii=False)
                    processed_since_last_save = 0


                time.sleep(DELAY_BASE + random.uniform(0, DELAY_JITTER))
            elif pano:
                point["status"] = "duplicate"
                point["source"] = SOURCE
                point["zoom"] = ZOOM_LEVEL
                point["duplicate_of"] = pano.id  # <‚Äì —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –Ω–µ –¥–ª—è –ª–æ–≥–∏–∫–∏
                success = True
                log(f"üîÑ –î—É–±–ª–∏–∫–∞—Ç: pano_id {pano.id} ‚Äî –Ω–∞–π–¥–µ–Ω –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ ({lat:.6f}, {lon:.6f}), —É–∂–µ —Å–∫–∞—á–∞–Ω —Ä–∞–Ω–µ–µ")

            else:
                point["status"] = "no_pano"
                point["zoom"] = ZOOM_LEVEL
                point["source"] = SOURCE
                success = True
                log(f"üö´ –ü–∞–Ω–æ—Ä–∞–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ ({lat:.6f}, {lon:.6f}) ‚Äî {city}")

                time.sleep(0.5 + random.uniform(0, 0.5))
        except Exception as e:
            try_attempts += 1
            if try_attempts >= 2:
                point["status"] = "error"
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ ({lat}, {lon}) –ø–æ—Å–ª–µ 2 –ø–æ–ø—ã—Ç–æ–∫: {e}")
                #log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ ({lat}, {lon}) –ø–æ—Å–ª–µ 2 –ø–æ–ø—ã—Ç–æ–∫: {e}")
                log(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ ({lat:.6f}, {lon:.6f}): {type(e).__name__} ‚Äî {e}")

            else:
                time.sleep(2)

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π JSON —Å–æ —Å—Ç–∞—Ç—É—Å–∞–º–∏ ===
with open(UPDATED_FILE, "w", encoding="utf-8") as f:
    json.dump(coords, f, indent=2, ensure_ascii=False)

f_csv.close()
print(f"\n‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ —Å–∫–∞—á–∞–Ω–æ –ø–∞–Ω–æ—Ä–∞–º: {count}")
log(f"üéØ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ —Å–∫–∞—á–∞–Ω–æ –ø–∞–Ω–æ—Ä–∞–º: {count}")

